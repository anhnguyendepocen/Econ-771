---
title: "Empirical Exercise 1: Hospital Data and Event Studies"
subtitle: "<html><div style='float:left'></div><hr color='#EB811B' size=1px width=0px></html>"
author: Ian McCarthy | Emory University
date: Econ 771 #"`r format(Sys.time(), '%d %B %Y')`"
header-includes: 
  - \usepackage{graphicx}
  - \usepackage{amsmath}
output:
#  html_document: default (toggle on for "simplified" view)
  xaringan::moon_reader:
    css: [default, metropolis, metropolis-fonts, custom.css, cols.css] 
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      beforeInit: [macros.js, cols_macro.js]
---

<!-- Adjust some CSS code for font size and maintain R code font size -->
<style type="text/css">
.remark-slide-content {
    font-size: 30px;
    padding: 1em 2em 1em 2em;    
}
.remark-code, .remark-inline-code { 
    font-size: 20px;
}
</style>


<!-- Set R options for how code chunks are displayed and load packages -->
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(
  fig.align="center",  
  fig.height=3, #fig.width=6,
  # out.width="748px", #out.length="520.75px",
  dpi=300, #fig.path='Figs/',
  cache=T#, echo=F, warning=F, message=F
  )

knitr::opts_hooks$set(fig.callout = function(options) {
  if(options$fig.callout) {
    options$echo = FALSE
  }
  options
})

if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, ggplot2, dplyr, lubridate, readr, readxl, hrbrthemes,
               scales, gganimate, gapminder, gifski, png, tufte, plotly, OECD,
               ggrepel, dtplyr, data.table, kableExtra, plotly, cobalt, stargazer, haven, ggthemes,
               magick, lfe, dotwhisker)
```


# Table of contents

1. [Overview](#overview)

2. [Workflow (in R)](#workflow)

3. [DD Identification Strategy](#id)

4. [Data](#data)

5. [Analysis](#analysis)

6. [Extras](#extras)


<!-- New Section -->
---
class: inverse, center, middle
name: overview

# Overview

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Goals of this assignment

1. Work with data on hospital characteristics
2. Estimate standard DD and 2WFE model
3. Estimate event studies

<br>
--
Plus the sub-goal for all assignments...practice your Git/GitHub workflow, version control, and replicability


---
# Specific "research question"

What effect did the Medicaid expansion have on hospital disproportionate share?

- Economics: expanding insurance should improve a hospital's finances
- Given DSH measurement in our data, Medicaid expansion should increase DSH (why?)



<!-- New Section -->
---
class: inverse, center, middle
name: workflow

# Workflow in R

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Data workflow

Some quick thoughts on workflow

1. Never use absolute path names!

<br>
.center[
  ![](https://media.giphy.com/media/3oz8xt6aO8l4UjcnXa/giphy.gif)
]

---
count: false

# Data workflow

Some quick thoughts on workflow

1. Never use absolute path names!

2. If you use the same data across projects, try a "path" script that you add to your `.gitignore` file


.center[
  ![](https://media.giphy.com/media/z8rEcJ6I0hiUM/giphy.gif)
]



---
count: false

# Data workflow

Some quick thoughts on workflow...

1. Never use absolute path names!

2. If you use the same data across projects, try a "path" script that you add to your `.gitignore` file

3. Separate your analysis and your markdown (not practical otherwise)


---
# My project workflow

.pre[
```
project
|   README.md
|   RunRender.Rmd
|   paper.Rmd
|   abstract.Rmd
|   presentation.Rmd
|   BibTeX.tex (google drive link)
|
|---analysis
|   |   _BuildFinalData.R
|   |   _Analysis.R
|   |   1_data1.R
|   |   2_data2.R
|   |   README.md (optional)
|
|---data
|   |   final_dat1.Rds (or csv)
|   |   final_dat2.Rds (or csv)
|
|---tables
|   |   table1.tex
|   |   table2.tex
| 
|---figures
|   |   figure1.png
|   |   figure2.png
```
]


---
# My assignment workflow

1. Do analysis and save main objects (not full datasets) in `workspace.Rdata`
2. Render markdown file as PDF

<br>
--
.pre[
````

```{r, eval=FALSE}`r ''`
title: "Exercise 1 Solutions"
author: Ian McCarthy, Econ 771
date: Fall 2020
geometry: "left=2cm,right=2cm,top=1cm,bottom=2cm"
fontsize: 12pt
subparagraph: yes
header-includes:
   - \usepackage{setspace}
   - \usepackage{titlesec}
   - \titlespacing{\title}{0pt}{\parskip}{-\parskip}
   - \titlespacing{\section}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
   - \titlespacing{\subsection}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
   - \titlespacing{\subsubsection}{0pt}{12pt plus 2pt minus 1pt}{0pt plus 1pt minus 1pt}
   - \usepackage{float}
output: 
  bookdown::pdf_document2:
    keep_tex: TRUE
    toc: FALSE
    number_sections: FALSE
    fig_caption: yes
bibliography: '../BibTeX_Library.bib'

{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse, ggplot2, dplyr, lubridate, stargazer, knitr, kableExtra, lfe)


{r, include=FALSE}
load("workspace.Rdata")


\setstretch{1.5}

# Overview
Hello world

```

````
]


<!-- New Section -->
---
class: inverse, center, middle
name: id

# The DD Research Design/Identification Strategy

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Setup
Want to estimate $E[Y_{1}(1)- Y_{0}(1) | W=1]$

![:col_header , Post-period, Pre-period]
![:col_row Treated, $E(Y_{1}(1)|W=1)$, $E(Y_{0}(0)|W=1)$]
![:col_row Control, $E(Y_{0}(1)|W=0)$, $E(Y_{0}(0)|W=0)$]

<br>
Problem: We don't see $E[Y_{0}(1)|W=1]$


---
# Setup
![:col_header , Post-period, Pre-period]
![:col_row Treated, $E(Y_{1}(1)|W=1)$, $E(Y_{0}(0)|W=1)$]
![:col_row Control, $E(Y_{0}(1)|W=0)$, $E(Y_{0}(0)|W=0)$]

<br>
Strategy 1: Estimate $E[Y_{0}(1)|W=1]$ using $E[Y_{0}(0)|W=1]$ (before treatment outcome used to estimate post-treatment)


---
# Setup
![:col_header , Post-period, Pre-period]
![:col_row Treated, $E(Y_{1}(1)|W=1)$, $E(Y_{0}(0)|W=1)$]
![:col_row Control, $E(Y_{0}(1)|W=0)$, $E(Y_{0}(0)|W=0)$]

<br>
Strategy 2: Estimate $E[Y_{0}(1)|W=1]$ using $E[Y_{0}(1)|W=0]$ (control group used to predict outcome for treatment)


---
# Setup
![:col_header , Post-period, Pre-period]
![:col_row Treated, $E(Y_{1}(1)|W=1)$, $E(Y_{0}(0)|W=1)$]
![:col_row Control, $E(Y_{0}(1)|W=0)$, $E(Y_{0}(0)|W=0)$]

<br>
Strategy 3: DD estimate...

<br>
Estimate $E[Y_{1}(1)|W=1] - E[Y_{0}(1)|W=1]$ using $E[Y_{0}(1)|W=0] - E[Y_{0}(0)|W=0]$ (pre-post difference in control group used to predict difference for treatment group)

---
# Animations!

.center[
  ![:scale 900px](dd_animate.gif)
]

---
# Estimation
Key identifying assumption is that of *parallel trends*

--
<br>
<br>
$$E[Y_{0}(1) - Y_{0}(0)|W=1] = E[Y_{0}(1) - Y_{0}(0)|W=0]$$

---
# Estimation
Sample means:<br>
$$\begin{align}
E[Y_{1}(1) - Y_{0}(1)|W=1] &=& \left( E[Y(1)|W=1] - E[Y(1)|W=0] \right) \\
 & & - \left( E[Y(0)|W=1] - E[Y(0)|W=0]\right)
\end{align}$$


---
# Estimation
Regression:<br>
$Y_{i} = \alpha + \beta W_{i} + \lambda 1(Post) + \delta W_{i} \times 1(Post) + \varepsilon$

<br>
![:col_header , After, Before, After - Before]
![:col_row Treated, $\alpha + \beta + \lambda + \delta$, $\alpha + \beta$, $\lambda + \delta$]
![:col_row Control, $\alpha + \lambda$, $\alpha$, $\lambda$]
![:col_row Treated - Control, $\beta + \delta$, $\beta$, $\delta$]


---
# Simulated data
```{r}
N <- 5000
dd.dat <- tibble(
  w = (runif(N, 0, 1)>0.5),
  time_pre = "pre",
  time_post = "post"
)

dd.dat <- pivot_longer(dd.dat, c("time_pre","time_post"), values_to="time") %>%
  select(w, time) %>%
  mutate(t=(time=="post"),
         y.out=1.5+3*w + 1.5*t + 6*w*t + rnorm(N*2,0,1))
```


---
# Mean differences
```{r}
dd.means <- dd.dat %>% group_by(w, t) %>% summarize(mean_y = mean(y.out))
knitr::kable(dd.means, col.names=c("Treated","Post","Mean"), format="html")
```

---
# Mean differences
In this example:
- $E[Y(1)|W=1] - E[Y(1)|W=0]$ is `r dd.means[4,3]-dd.means[2,3]`
- $E[Y(0)|W=1] - E[Y(0)|W=0]$ is `r dd.means[3,3]-dd.means[1,3]`

<br>
<br>
So the ATT is `r as.numeric(dd.means[4,3])-as.numeric(dd.means[2,3]) - (as.numeric(dd.means[3,3])-as.numeric(dd.means[1,3]))`

---
# Regression estimator
.pre[
```{r}
dd.est <- lm(y.out ~ w + t + w*t, data=dd.dat)
summary(dd.est)
```
]

---
# TWFE

With multiple groups and multiple time periods, including fixed effects for each group and each year (*two*-way fixed effects) is a more general specification

<br>
--
But it's still just DD. We'll come back to this shortly.



<!-- New Section -->
---
class: inverse, center, middle
name: data

# Data

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Data sources

1. Inpatient Prospective Payment System Final Rule Files, available [here](https://data.nber.org/data/cms-impact-file-hospital-inpatient-prospective-payment-system-ipps.html) from the NBER.

2. Provider of Services files, available [here](https://data.nber.org/data/provider-of-services.html) from the NBER. 

3. Medicaid expansion, available [here](https://www.kff.org/medicaid/issue-brief/status-of-state-medicaid-expansion-decisions-interactive-map/) from the Kaiser Family Foundation.


---
# IPPS Data

Let's start with a quick look at the 1994 data

.pre[
```{r echo=TRUE, warnings=FALSE}
source('../paths.R')
ipps.example <- read_csv(paste0(ipps.path,"/impact1994.csv"))
head(ipps.example)
```
]

---
count: false

# IPPS Data

Let's start with a quick look at the 1994 data

.pre[
```{r echo=TRUE, warnings=FALSE}
glimpse(ipps.example)
```
]

---
# IPPS Data

Data exist in three groups...

1. 1986 to 1993: case mix index (CMI) and wage index
2. 1994 to 2000: adds adjusted cases, daily census, beds, DSH percent, and provider type
3. 2001 to 2018: change to variable name and format for provider type

<br>
--
**provider** is the Medicare provider number and the unique hospital ID for these data

---
# POS Data

Let's start with a quick look at the 1994 data

.pre[
```{r echo=TRUE, warnings=FALSE}
pos.example <- read_csv(paste0(pos.path,"/pos1994.csv/pos1994.csv"))
head(pos.example)
```
]


---
count: false

# POS Data

Let's start with a quick look at the 1994 data

.pre[
```{r echo=TRUE, warnings=FALSE}
glimpse(pos.example)
```
]


---
# POS Data, 1984 to 1990

.pre[
```{r, eval=F}
for (y in 1984:1990) {
  pos.data <- read_csv(paste0(pos.path,"/pos",y,".csv/pos",y,".csv"))
  
  pos.data <- pos.data %>%
    rename(provider=prov1680,
           own_change=prov0100,
           beds_cert=prov0755,
           beds_tot=prov0740,
           name=prov0475,
           street=prov2720,
           city_state=prov0115,
           zip=prov2905,
           fac_type=prov2890,
           own_type=prov2885,
           term_date=prov2810) %>%
    mutate(term_date=as.Date(as.character(term_date), format='%y%m%d'),
           own_change=as.Date(as.character(term_date), format='%y%m%d'),
           state=str_sub(city_state, start=-2),
           city=str_sub(city_state, start=1, end=-2),
           year=y) %>%
    select(provider, category, own_change, beds_cert, beds_tot, name,
           street, city, state, zip, term_date, fac_type, own_type, year) %>%
    filter(provider!='000000')

  assign(paste0("pos.",y),pos.data)  
}
```
]

---
# POS Data, 1991

.pre[
```{r, eval=F}
y=1991
pos.data <- read_csv(paste0(pos.path,"/pos",y,".csv/pos",y,".csv"))

pos.data <- pos.data %>%
  rename(category=prvdr_ctgry_cd,
         category_sub=prvdr_ctgry_sbtyp_cd,
         provider=prvdr_num,
         own_change=chow_dt,
         beds_cert=crtfd_bed_cnt,
         beds_tot=bed_cnt,
         name=fac_name,
         street=st_adr,
         city_state=prov0115,
         zip=zip_cd,
         fac_type=gnrl_fac_type_cd,
         own_type=gnrl_cntl_type_cd,
         term_date=prov2810) %>%
  mutate(term_date=as.Date(as.character(term_date), format='%y%m%d'),
         own_change=as.Date(as.character(term_date), format='%y%m%d'),
         state=str_sub(city_state, start=-2),
         city=str_sub(city_state, start=1, end=-2),
         year=y) %>%
  select(provider, category, category_sub, own_change, beds_cert, beds_tot, name,
         street, city, state, zip, term_date, fac_type, own_type, year) %>%
  filter(provider!='000000')
```
]



---
# POS Data, 1992 to 1993

.pre[
```{r, eval=F}
for (y in 1992:1993) {
  pos.data <- read_csv(paste0(pos.path,"/pos",y,".csv/pos",y,".csv"))
  
  pos.data <- pos.data %>%
    rename(category=prvdr_ctgry_cd,
           category_sub=prvdr_ctgry_sbtyp_cd,           
           provider=prvdr_num,
           own_change=chow_dt,
           beds_cert=crtfd_bed_cnt,
           beds_tot=bed_cnt,
           name=fac_name,
           street=st_adr,
           zip=zip_cd,
           own_type=gnrl_cntl_type_cd,
           term_date=prov2810,
           state=state_cd) %>%
    mutate(term_date=as.Date(as.character(term_date), format='%y%m%d'),
           own_change=as.Date(as.character(term_date), format='%y%m%d'),
           year=y) %>%
    select(provider, category, category_sub, own_change, beds_cert, beds_tot, name,
           street, city, state, zip, term_date, own_type, year)
  
  assign(paste0("pos.",y),pos.data)  
}
```
]


---
# POS Data, 1994

.pre[
```{r, eval=F}
y=1994
pos.data <- read_csv(paste0(pos.path,"/pos",y,".csv/pos",y,".csv"))
pos.data <- pos.data %>%
  rename(category=prvdr_ctgry_cd,
         category_sub=prvdr_ctgry_sbtyp_cd,         
         provider=prvdr_num,
         own_change=chow_dt,
         beds_cert=crtfd_bed_cnt,
         beds_tot=bed_cnt,
         name=fac_name,
         street=st_adr,
         zip=zip_cd,
         own_type=gnrl_cntl_type_cd,
         term_date=trmntn_exprtn_dt,
         state=state_cd) %>%
  mutate(term_date=as.Date(as.character(term_date), format='%y%m%d'),
         own_change=as.Date(as.character(term_date), format='%y%m%d'),
         year=y) %>%
  select(provider, category, category_sub, own_change, beds_cert, beds_tot, name,
         street, city, state, zip, term_date, own_type, year)
assign(paste0("pos.",y),pos.data)
```
]


---
# POS Data, 1995 to 2010

.pre[
```{r, eval=F}
for (y in 1995:2010) {
  pos.data <- read_csv(paste0(pos.path,"/pos",y,".csv/pos",y,".csv"))
  pos.data <- pos.data %>%
    rename(category=prvdr_ctgry_cd,
           category_sub=prvdr_ctgry_sbtyp_cd,           
           provider=prvdr_num,
           own_change=chow_dt,
           beds_cert=crtfd_bed_cnt,
           beds_tot=bed_cnt,
           name=fac_name,
           street=st_adr,
           zip=zip_cd,
           own_type=gnrl_cntl_type_cd,
           term_date=trmntn_exprtn_dt,
           state=state_cd) %>%
    mutate(term_date=as.Date(as.character(term_date), format='%Y%m%d'),
           own_change=as.Date(as.character(term_date), format='%Y%m%d'),
           year=y) %>%
    select(provider, category, category_sub, own_change, beds_cert, beds_tot, name,
           street, city, state, zip, term_date, own_type, year)
  
  assign(paste0("pos.",y),pos.data)  
}
```
]


---
# POS Data, 2011 to 2018

.pre[
```{r, eval=F}
for (y in 2011:2018) {
  pos.data <- read_csv(paste0(pos.path,"/pos",y,".csv/pos",y,".csv"))
  colnames(pos.data) <- tolower(colnames(pos.data))
  
  pos.data <- pos.data %>%
    rename(category=prvdr_ctgry_cd,
           category_sub=prvdr_ctgry_sbtyp_cd,           
           provider=prvdr_num,
           own_change=chow_dt,
           beds_cert=crtfd_bed_cnt,
           beds_tot=bed_cnt,
           name=fac_name,
           street=st_adr,
           zip=zip_cd,
           city=city_name,
           own_type=gnrl_cntl_type_cd,
           term_date=trmntn_exprtn_dt,
           state=state_cd) %>%
    mutate(term_date=as.Date(as.character(term_date), format='%Y%m%d'),
           own_change=as.Date(as.character(term_date), format='%Y%m%d'),
           year=y) %>%
    select(provider, category, category_sub, own_change, beds_cert, beds_tot, name,
           street, city, state, zip, term_date, own_type, year)
  
  assign(paste0("pos.",y),pos.data)  
}
```
]


---
# Medicaid expansion data

- Available from Kaiser Family Foundation
- Need to crosswalk state abbreviations with full state name

---
# Medicaid expansion data

.pre[
```{r, eval=F}
kff.dat <- read_csv(file=paste0(kff.path,'/KFF_medicaid_expansion_2019.csv'))

kff.final <- kff.dat %>%
  mutate(expanded = (`Expansion Status` == 'Adopted and Implemented'),
         Description = str_replace_all(Description,c("\n"='','"'='')))

kff.final$splitvar <- kff.final %>% select(Description) %>% as.data.frame() %>%
  separate(Description, sep=" ", into=c(NA, NA, NA, "date"))

kff.final <- kff.final %>%
  mutate(date_adopted = mdy(splitvar$date),
         expand_year = year(date_adopted)) %>%
  rename(state=State) %>%
  left_join(state.xw, by=c("state"))
```
]

<!-- New Section -->
---
class: inverse, center, middle
name: analysis

# Analysis

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Summary Statistics

- Generating summary statistics is easy
- Nicely presenting summary statistics is harder (especially in R)
- Some `R` packages to try: `vtable::sumtable()`, `modelsummary`, `stargazer`
- My approach: manual objects and `knitr::kable()`


---
# Summary Statistics

```{r, eval=F}
sum.stats <- full.data %>% ungroup() %>%
  group_by(year) %>%
  summarize_at(c("cmi","dshpct"), list(mean, sd, min, max), na.rm=TRUE) %>%
  filter(year>=1986) %>%
  select(year, cmi_fn1, cmi_fn2, cmi_fn3, cmi_fn4, 
         dshpct_fn1, dshpct_fn2, dshpct_fn3, dshpct_fn4) %>%
  mutate_if(is.numeric, ~ifelse(abs(.) == Inf, NA, .))
```


---
count: false

# Summary Statistics

```{r, include=F, eval=T}
load('../solutions/exercise1/workspace.Rdata')
```

```{r, eval=F}
options(knitr.kable.NA = '')
knitr::kable(sum.stats, 
             col.names=c("Year", "Mean", "Std. Dev.", "Min", "Max", "Mean", "Std. Dev.", "Min", "Max"),
             digits=2,
             caption = "Summary Statistics", 
             booktabs = TRUE,
             escape=F,
             align=c("l","r","r","r","r","r","r","r","r"),
             position="h") %>% 
  kable_styling(full_width=F) %>%
  add_header_above(c(" " = 1, "Case Mix Index" = 4,"Disproportionate Share" = 4)) %>%
  scroll_box(width="100%", height = "400px")
```

---
count: false

# Summary Statistics

.pre[
```{r, echo=F}
options(knitr.kable.NA = '')
knitr::kable(sum.stats, "html",
             col.names=c("Year", "Mean", "Std. Dev.", "Min", "Max", "Mean", "Std. Dev.", "Min", "Max"),
             digits=2,
             caption = "Summary Statistics", 
             booktabs = TRUE,
             escape=F,
             align=c("l","r","r","r","r","r","r","r","r"),
             position="h") %>% 
  kable_styling(full_width=F) %>%
  add_header_above(c(" " = 1, "Case Mix Index" = 4,"Disproportionate Share" = 4))
```
]

---
# Regressions

Standard DD:

$$DSH_{ht} = \alpha Expand_{s} + \beta \times 1(t\geq 2014) + \delta Expand_{s} \times 1(t\geq 2014) + \varepsilon_{ht}$$

<br>
--
Implementing this in `R`:
```{r, eval=F}
dd.est <- lm(dshpct~post + expand_ever + treat, data=reg.data)
```

---
# Regressions

Two-way fixed effects:

$$DSH_{ht} = \delta Expand_{s} \times (t\geq 2014) + \lambda_{h} + \gamma_{t} + \varepsilon_{ht}$$

<br>
--
Implementing this in `R`:
```{r, eval=F}
lfe.est <- felm(dshpct~treat | provider + year, data=reg.data)
```

..could also try `fixest` package.


---
# Event study with single treatment

.pre[
```{r, eval=F}
event.dat <- reg.data %>%
  mutate(expand_2005 = expand_ever*(year==2005),
         expand_2006 = expand_ever*(year==2006),
         expand_2007 = expand_ever*(year==2007),
         expand_2008 = expand_ever*(year==2008),
         expand_2009 = expand_ever*(year==2009),
         expand_2010 = expand_ever*(year==2010),
         expand_2011 = expand_ever*(year==2011),
         expand_2012 = expand_ever*(year==2012),
         expand_2013 = expand_ever*(year==2013),
         expand_2014 = expand_ever*(year==2014),
         expand_2015 = expand_ever*(year==2015),
         expand_2016 = expand_ever*(year==2016),
         expand_2017 = expand_ever*(year==2017),
         expand_2018 = expand_ever*(year==2018))

event.reg <- felm(dshpct ~ expand_2005 + expand_2006 + expand_2007 +
                        expand_2008 + expand_2009 + expand_2010 + expand_2011 + expand_2012 + expand_2014 + 
                        expand_2015 + expand_2016 + expand_2017 + 
                        expand_2018 | year + provider, data=event.dat)

point.est <- as_tibble(c(event.reg$coefficients[c("expand_2005","expand_2006","expand_2007",
                                                      "expand_2008","expand_2009","expand_2010", "expand_2011",
                                                      "expand_2012","expand_2014","expand_2015",
                                                      "expand_2016","expand_2017","expand_2018"),]),
                       rownames = "term")
ci.est <- as_tibble(confint(event.reg)[c("expand_2005","expand_2006","expand_2007",
                                             "expand_2008","expand_2009","expand_2010","expand_2011",
                                             "expand_2012","expand_2014","expand_2015",
                                             "expand_2016","expand_2017","expand_2018"),],
                    rownames = "term")
point.est <- point.est %>% rename(estimate = value)
ci.est <- ci.est %>% rename(conf.low = `2.5 %`, conf.high = `97.5 %`)
new.row <- tibble(
  term = "expand_2013",
  estimate = 0,
  conf.low = 0,
  conf.high = 0,
  year = 2013
)

event.plot.dat <- point.est %>%
  left_join(ci.est, by=c("term")) %>%
  mutate(year = c(2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2014, 2015, 2016, 2017, 2018)) %>%
  bind_rows(new.row) %>%
  arrange(year)

event.plot <- dwplot(event.plot.dat, 
                     vline=geom_vline(xintercept=0, linetype=2), 
                     order_vars = c("expand_2018","expand_2017","expand_2016",
                                    "expand_2015","expand_2014","expand_2013",
                                    "expand_2012","expand_2011","expand_2010",
                                    "expand_2009","expand_2008","expand_2007",
                                    "expand_2006","expand_2005"),
                     whisker_args = list(color="black", size=1.1),
                     dot_args = list(color="black")) + 
  coord_flip() + theme_bw() + theme(legend.position = "none") +
  labs(y = "Year",
       x = "Estimate and 95% CI") +
  scale_y_discrete(labels = c("expand_2005" = "2005", 
                              "expand_2006" = "2006", 
                              "expand_2007" = "2007", 
                              "expand_2008" = "2008", 
                              "expand_2009" = "2009", 
                              "expand_2010" = "2010", 
                              "expand_2011" = "2011", 
                              "expand_2012" = "2012", 
                              "expand_2013" = "2013",
                              "expand_2014" = "2014",
                              "expand_2015" = "2015",
                              "expand_2016" = "2016",
                              "expand_2017" = "2017",
                              "expand_2018" = "2018"))
```
]

---
count: false

# Event study with single treatment

.center[
```{r echo=FALSE}
event.plot
```
]


---
# Event study with time-varying treatment

.pre[
```{r, eval=F}
reg.data2 <- full.data %>%
  filter(year>=2005,
         year<=2018) %>%
  mutate(treat=case_when(
    year>=expand_year & !is.na(expand_year) ~ 1,
    is.na(expand_year) ~ 0,
    year<expand_year & !is.na(expand_year) ~ 0)
  )


event.dat2 <- reg.data2 %>%
  mutate(event_time=case_when(
    !is.na(expand_year) ~ year-expand_year ,
    is.na(expand_year) ~ -1)) %>%
  mutate(time_m12=1*(event_time<=-12),
         time_m11=1*(event_time==-11),
         time_m10=1*(event_time==-10),
         time_m9=1*(event_time==-9),
         time_m8=1*(event_time==-8),
         time_m7=1*(event_time==-7),
         time_m6=1*(event_time==-6),
         time_m5=1*(event_time==-5),
         time_m4=1*(event_time==-4),
         time_m3=1*(event_time==-3),
         time_m2=1*(event_time==-2),
         time_0=1*(event_time==0),
         time_p1=1*(event_time==1),
         time_p2=1*(event_time==2),
         time_p3=1*(event_time==3),
         time_p4=1*(event_time==4))

event.reg2 <- felm(dshpct ~ time_m12 + time_m11 + time_m10 + time_m9 + time_m8 +
                       time_m7 + time_m6 + time_m5 + time_m4 + time_m3 + time_m2 + time_0 +
                       time_p1 + time_p2 + time_p3 + time_p4 |
                       year + provider, data=event.dat2)

point.est2 <- as_tibble(event.reg2$coefficients, rownames="term")
point.est2 <- point.est2 %>% filter(term %in% c("time_m12","time_m11", "time_m10", "time_m9",
                                                "time_m8", "time_m7", "time_m6", "time_m5",
                                                "time_m4","time_m3","time_m2","time_0",
                                                "time_p1","time_p2","time_p3","time_p4"))
ci.est2 <- as_tibble(confint(event.reg2), rownames="term")
ci.est2 <- ci.est2 %>% filter(term %in% c("time_m12","time_m11", "time_m10", "time_m9",
                                          "time_m8", "time_m7", "time_m6", "time_m5",
                                          "time_m4","time_m3","time_m2","time_0",
                                          "time_p1","time_p2","time_p3","time_p4"))

point.est2 <- point.est2 %>% rename(estimate = dshpct)
ci.est2 <- ci.est2 %>% rename(conf.low = `2.5 %`, conf.high = `97.5 %`)
new.row <- tibble(
  term = "time_m1",
  estimate = 0,
  conf.low = 0,
  conf.high = 0,
  event_time = -1
)

event.plot.dat2 <- point.est2 %>%
  left_join(ci.est2, by=c("term")) %>%
  mutate(event_time = c(-12, -11, -10, -9, -8, -7, -6, -5, -4,-3,-2,0,1,2,3,4)) %>%
  bind_rows(new.row) %>%
  arrange(event_time)

event.plot2 <- dwplot(event.plot.dat2, 
                      vline=geom_vline(xintercept=0, linetype=2), 
                      order_vars = c("time_p4","time_p3","time_p2",
                                     "time_p1","time_0","time_m1",
                                     "time_m2","time_m3","time_m4",
                                     "time_m5","time_m6","time_m7",
                                     "time_m8","time_m9","time_m10",
                                     "time_m11","time_m12"),
                      whisker_args = list(color="black", size=1.1),
                      dot_args = list(color="black")) + 
  coord_flip() + theme_bw() + theme(legend.position = "none") +
  labs(y = "Year",
       x = "Estimate and 95% CI") +
  scale_y_discrete(labels = c("time_p4" = "t+4", 
                              "time_p3" = "t+3",
                              "time_p2" = "t+2",
                              "time_p1" = "t+1",
                              "time_0" = "0",
                              "time_m1" = "t-1",
                              "time_m2" = "t-2",
                              "time_m3" = "t-3",
                              "time_m4" = "t-4",
                              "time_m5" = "t-5",
                              "time_m6" = "t-6",
                              "time_m7" = "t-7",
                              "time_m8" = "t-8",
                              "time_m9" = "t-9",
                              "time_m10" = "t-10",
                              "time_m11" = "t-11",
                              "time_m12" = "t-12+"))
```
]


---
count: false

# Event study with time-varying treatment

.center[
```{r echo=FALSE}
event.plot2
```
]


<!-- New Section -->
---
class: inverse, center, middle
name: extras

# Extras

<html><div style='float:left'></div><hr color='#EB811B' size=1px width=1055px></html>


---
# Back to the TWFE estimator

$Y_{it} = \alpha_{i} + \gamma_{t} + \delta W_{it} + \varepsilon_{it}$

<br>
--

1. Some simple simulations
2. Discuss what we're really estimating
3. Some new approaches and tools


---
# Simulated data

.pre[
```{r}
N <- 5000
twfe.dat <- tibble(
  id = seq(1:N),
  w = as.numeric((runif(N, 0, 1)>0.5)),
  xi = rnorm(N,0,2),
  treat_year = sample(x=2010:2015,N,replace=T)
)

twfe.final <- twfe.dat %>%
  mutate(year=2000)

for (t in 2001:2020) {
  twfe.dat <- twfe.dat %>%
    mutate(year=t)
  twfe.final <- twfe.final %>%
    bind_rows(twfe.dat)
}
N_t=nrow(twfe.final)

twfe.final <- twfe.final %>%
  mutate(treat = (year>=treat_year)*w,
         treat_year = case_when(
           w==1 ~ treat_year,
           w==0 ~ NA_integer_)) %>%
  select(id, treat, w, xi, year, treat_year) %>%
  mutate(y_out = 1.5+3*w -2*xi + 1.5*(year-2009) + 6*treat + rnorm(N_t,0,1))
```
]


---
# DD versus TWFE
Focus on a specific treatment group and compare DD/TWFE estimates

```{r, include=T, echo=F}
twfe.2010 <- twfe.final %>% mutate(post=(year>=2010)) %>% filter(is.na(treat_year) | treat_year==2010)
```

.pull-left[
.pre[
```{r}
summary(lm(y_out~treat + w + post, data=twfe.2010))
```
]

]

.pull-right[
.pre[
```{r}
summary(felm(y_out~treat|id + year, data=twfe.2010))
```
]

]


---
# Allow treatment timing to vary

.pre[
```{r}
summary(felm(y_out~treat|id + year, data=twfe.final))
```
]

---
# What are we estimating?

$Y_{it} = \alpha_{i} + \gamma_{t} + \delta W_{it} + \varepsilon_{it}$

Getting a consistent estimate of $\delta$ requires:

1. Correctly specified functional form
2. **Strict** exogeneity
  - no unobserved confounders
  - past outcomes don't directly affect current outcome
  - past treatments don't directly affect current outcome
  - past outcomes don't direclty affect current treatment

---
count: false

# What are we estimating?

$Y_{it} = \alpha_{i} + \gamma_{t} + \delta W_{it} + \varepsilon_{it}$

But what parameter is this? Is it interesting?

<br>
--

- Only an average effect if we assume homogeneous treatment effects
- Using standard within estimator, we get a variance weighted average treatment effect

---
# What does "heterogeneous" treatment effects mean

.pull-left[
**Across Units**

- TWFE estimator still recovers the ATT **if** heterogeneities are random
- selective treatment timing is not allowed **at all** (even if time-invariant)
- why? correlation means variance weights on ATT no longer equal to OLS

]

.pull-right[
**Across Time** (dynamic effects)

- Not allowed in baseline TWFE
- Event study will help if this is the only source of heterogeneity

]

---
# Back to our estimation

$Y_{it} = \alpha_{i} + \gamma_{t} + \delta W_{it} + \varepsilon_{it}$

<br>
--

Goodman-Bacon (2019) shows that $\delta$ can be decomposed as follows:

$\hat{\delta} = \text{ATT}_{vw} + \text{CT}_{vw} - \Delta \text{ATT}$

---
# Understanding TWFE

$\hat{\delta} = \color{red}{\text{VW-ATT}} + \text{VW-CT} - \Delta \text{ATT}$

- variance-weighted average treatment effect (on the treated)
- $=$ ATT only if weights are equal to variance of treatment dummy
- not the case with any selection into treatment


---
count: false

# Understanding TWFE

$\hat{\delta} = \text{VW-ATT} + \color{red}{\text{VW-CT}} - \Delta \text{ATT}$

- variance-weighted common trends
- $= 0$ if parallel trends assumption holds

---
count: false

# Understanding TWFE

$\hat{\delta} = \text{VW-ATT} + \text{VW-CT} - \color{red}{\Delta \text{ATT}}$

- offset to treatment effects using early treated units as control for future treated
- only matters with heterogeneous effects across units and variable treatmen timing



---
# What can we do?

1. Pay attention to treatment timing


---
count:false

# What can we do?

1. Pay attention to treatment timing

The `panelView` package is a great way to see who is treated in your data and over what time periods.


---
count:false

# What can we do?

1. Pay attention to treatment timing

```{r include=FALSE}
N <- 40
pview.dat <- tibble(
  id = seq(1:N),
  w = as.numeric((runif(N, 0, 1)>0.5)),
  xi = rnorm(N,0,2),
  treat_year = sample(x=2010:2015,N,replace=T)
)

pview.final <- pview.dat %>%
  mutate(year=2000)

for (t in 2001:2020) {
  pview.dat <- pview.dat %>%
    mutate(year=t)
  pview.final <- pview.final %>%
    bind_rows(pview.dat)
}
N_t=nrow(pview.final)

pview.final <- pview.final %>%
  mutate(treat = (year>=treat_year)*w,
         treat_year = case_when(
           w==1 ~ treat_year,
           w==0 ~ NA_integer_)) %>%
  select(id, treat, w, xi, year, treat_year) %>%
  mutate(y_out = 1.5+3*w -2*xi + 1.5*(year-2009) + 6*treat + rnorm(N_t,0,1))

```

```{r, echo=F, warning=F, message=F, comment=F}
library(panelView)
panelView(y_out~treat, data=data.frame(pview.final), index=c("id","year"),
          xlab="Year", ylab="ID",
          by.timing=TRUE, legend.labs=c("No Expansion", "Expansion"),
          background="white", cex.main=14, cex.axis=7, cex.lab=12, cex.legend=12)
```

---
count:false

# What can we do?

1. Pay attention to treatment timing


```{r, echo=F, warning=F, message=F, comment=F}
panelView(y_out~treat, data=data.frame(pview.final), index=c("id","year"),
          xlab="Year", ylab="ID",
          by.timing=TRUE, legend.labs=c("Never Expanded", "Pre-Expansion", "Post-Expansion"),
          background="white", cex.main=14, cex.axis=7, cex.lab=12, cex.legend=12,
          pre.post=TRUE)
```


---
count:false

# What can we do?

1. Pay attention to treatment timing
2. Estimate event studies for specific treatment groups


---
count:false

# What can we do?

1. Pay attention to treatment timing
2. Estimate event studies for specific treatment groups
3. Consider recent approaches in:
  - [Goodman-Bacon (2019)](https://cdn.vanderbilt.edu/vu-my/wp-content/uploads/sites/2318/2019/07/29170757/ddtiming_7_29_2019.pdf), `bacondecomp` in Stata and R
  - [de Chaisemartin and D'Haultfoeuille (2020)](https://www.aeaweb.org/articles?id=10.1257/aer.20181169), `twowayfeweights`, `fuzzy_did`, and `did_multiplegt` in Stata. R packages apparently [on the way](https://twitter.com/CdeChaisemartin/status/1263506539718914049)
  - [Callaway and Sant'Anna (2019)](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3148250), `did` package in R. Also check out Sant'Anna and Zhou's "doubly-robust" DD estimator package, `drdid`
  - Abraham and Sun (2020)
  
---
count: false

# Bacon Decomposition

```{r}
library(bacondecomp)
df.bacon <- bacon(y_out~treat, data=pview.final, id_var="id", time_var="year")
df.bacon
```

---
count: false

# Bacon Decomposition

```{r, include=F}
ggplot(df.bacon) +
  aes(x = weight, y = estimate, shape = factor(type)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  labs(x = "Weight", y = "Estimate", shape = "Type")  
```